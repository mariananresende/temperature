#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# !pip install streamlit requests google-generativeai python-dotenv


import streamlit as st
import requests
import os
import pandas as pd
from dotenv import load_dotenv
import google.generativeai as genai
import json

# ========= Carrega vari√°veis de ambiente =========
load_dotenv()

# Primeiro tenta pegar do .env
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")

# Se n√£o encontrar no .env, tenta no secrets (Streamlit Cloud)
if not GEMINI_API_KEY or not WEATHER_API_KEY:
    try:
        GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
        WEATHER_API_KEY = st.secrets["WEATHER_API_KEY"]
    except (FileNotFoundError, KeyError):
        pass  # vai continuar como None

# Valida√ß√£o b√°sica
if not GEMINI_API_KEY or not WEATHER_API_KEY:
    st.error("‚ö†Ô∏è API keys n√£o foram encontradas. Verifique o arquivo .env (modo local) ou secrets.toml (Streamlit Cloud).")
    st.stop()


# ========= Configura modelo =========
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# ========= Configura√ß√£o da p√°gina =========
st.set_page_config(page_title="Clima com IA", page_icon="üåç")
st.title("üå§Ô∏è Consulta de Temperatura com IA")

# ========= Fun√ß√£o: Extrai coordenadas com Nominatim =========
def get_coordinates_from_city(city_name):
    url = f"https://nominatim.openstreetmap.org/search?q={city_name}&format=json&limit=1"
    headers = {"User-Agent": "clima-com-ia"}
    response = requests.get(url, headers=headers)
    if response.status_code == 200 and response.json():
        data = response.json()[0]
        return float(data["lat"]), float(data["lon"])
    return None, None

# ========= Fun√ß√£o: Consulta clima por coordenadas =========
def get_weather_by_coordinates(lat, lon):
    url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric&lang=pt"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        return data["main"]["temp"], data["weather"][0]["description"], data["name"]
    return None, None, None

# ========= Sess√£o do chat =========
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])

# ========= Entrada do usu√°rio =========
user_input = st.chat_input("Pergunte a temperatura de qualquer cidade...")

if user_input:
    st.chat_message("user").markdown(user_input)

    # Prompt para decidir se √© um pedido de clima
    city_decision_prompt = f"""
    Voc√™ √© um assistente com acesso a fun√ß√µes. Aqui est√° uma fun√ß√£o dispon√≠vel:

    Fun√ß√£o: consultar_temperatura(cidade: string)
    Descri√ß√£o: Retorna a temperatura atual de uma cidade informada.

    O usu√°rio escreveu: '{user_input}'

    Sua tarefa √© decidir se deseja chamar a fun√ß√£o 'consultar_temperatura'.

    Se for um pedido para saber a temperatura de uma cidade (ou apenas o nome da cidade), 
    retorne o seguinte JSON, com o nome real da cidade no campo "cidade":
    {{
      "chamar_funcao": true,
      "cidade": "Dublin"
    }}


    Se a frase n√£o tiver rela√ß√£o com clima ou for sobre outros assuntos, 
    responda com este JSON:
    {{
      "chamar_funcao": false,
      "cidade": null
    }}

    Responda SOMENTE com o JSON. Sem explica√ß√µes, sem markdown.
    """

    decision = model.generate_content(city_decision_prompt)

    try:
        # Remove crases, blocos de c√≥digo e explica√ß√µes do retorno do modelo
        raw_response = decision.text.strip()

        # Remove crases, blocos de markdown, e deixa s√≥ o JSON
        cleaned_response = raw_response.replace("```json", "").replace("```", "").strip()

        decision_json = json.loads(cleaned_response)



        if decision_json.get("chamar_funcao") and decision_json.get("cidade"):
            city_name = decision_json["cidade"]
            lat, lon = get_coordinates_from_city(city_name)

            if lat and lon:
                temp, desc, local_nome = get_weather_by_coordinates(lat, lon)
                if temp is not None:
                    resposta = model.generate_content(
                        f"A temperatura atual em {local_nome} √© de {temp}¬∞C com {desc}. "
                        f"Responda ao usu√°rio de forma simp√°tica e natural em portugu√™s, como um assistente amig√°vel."
                    )
                else:
                    resposta = model.generate_content(
                        f"A cidade {city_name} foi encontrada, mas o clima n√£o p√¥de ser consultado. "
                        f"Pe√ßa desculpas e sugira tentar mais tarde."
                    )
            else:
                resposta = model.generate_content(
                    f"A cidade '{city_name}' n√£o p√¥de ser localizada. "
                    f"Pe√ßa desculpas e oriente o usu√°rio a verificar a grafia ou tentar outra cidade."
                )
        else:
            resposta_texto = (
                "Desculpe! Sou um assistente especializado em clima. "
                "Voc√™ pode me perguntar, por exemplo: 'Qual a temperatura em Lisboa?' üåç"
            )

    except Exception as e:
        resposta = model.generate_content(
            f"Houve um erro ao interpretar a solicita√ß√£o: {str(e)}. Pe√ßa desculpas e oriente o usu√°rio a tentar novamente."
        )

    # Renderiza√ß√£o da resposta
    if "resposta" in locals():
        st.chat_message("assistant").markdown(resposta.text)
    elif "resposta_texto" in locals():
        st.chat_message("assistant").markdown(resposta_texto)

    # Mostra o mapa se houver coordenadas v√°lidas
    if 'lat' in locals() and lat and lon:
        st.map(pd.DataFrame({"lat": [lat], "lon": [lon]}))




